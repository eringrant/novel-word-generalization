# This is the config file for the first simulation in CogSci 2011 paper: comparing
# learning patterns of differnt learners, using wordnet prob data (as opposed to
# sensory data used in the original simulations)

[Smoothing]

# All Required
# Meaning probability smoothing
beta=10000
lambda=-1
# Rate at which Lambda decreases over time - "c" is in first paper concerning LTs and NDs 
power=1
# Alignment probability smoothing
alpha=20
epsilon=0.01

[Similarity]
# All Required
# Similarity measure used for evaluation
# Accepted Types: COS, JSD, EUC, AP. See constants.py for details.
simtype=COS
# Threshold to determine whether a word has been acquired/learned
theta=0.7

[Features]
# All optional
dummy=false
forget=false
forget-decay=0
novelty=false
novelty-decay=0
# Required. If ACT, forget must be true.
# Accepted Types: SUM, ACT, DEC_SUM. See constants.py for details.
#	DEC_SUM requires a forget decay, as it is a "forgetting" based assoc type.
assoc-type=SUM

# to grow a semantic network or not
semantic-network=false
hub-type=hub-freq-degree
hub-num=75


[Statistics]
# Optional
#traceword=test
# Required, Record stats flag
stats=true
# Required, Record context related stats flag
context-stats=false
familiarity-smoothing=0.01
# Familiarty Measure is required for context-stats. The accepted values
# are FREQ, LOG_FREQ, and COUNT. See ContextPropsTable.familiarity
# function comments in statistics.py for details.
familiarity-measure=COUNT
age-of-exposure-norm=100
# The following are Required if stats=true, disregarded otherwise. 
# Accepted Tags: ALL, N, V, OTH. See constants.py for details.
tag1=ALL
# Optional if tag1 is anything but ALL
#tag2=V
#tag3=
# Prefixes of the properties files to be created while recording statistics
word-props-name=word_props_
time-props-name=time_props_
context-props-name=context_props


[Other]
# All optional
# Minimum number of occurrences a word must have before it can be considered learned
minfreq=0
# Number of iterations after which properties will be written to files
record-iterations=-1
# Maximum number of time steps the model will run for
maxtime=1000
# Maximum number of words the model will learn
maxlearned=-1
# Skip processing utterances of only a single word
remove-singleton-utterances=false
