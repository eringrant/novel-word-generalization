Model parameters:
lambda: initially set to -1
beta: initially set to 10000; set initial probability of a feature for a word to 1/beta
alpha: initially set to 20; set initial alignment of a word-feature to 1/alpha
epsilon: initially set to 0.01; add to numerator when calculating alignment of a word given a feature
theta: initially set to 0.7; learning threshold

Code roadmap:
1) initialise all config parameter settings
2) generate gold standard lexicon (word to feature to probability map) (learn.py line 167)
3) generate initial empty lexicon (learn.py line 171)
4) receive words-features input pairs from the corpus (main.py line 104)
    a) time incremented by 1 unit after each words-features pair is processed
    b) loop over each feature: do
        i) initiase a sum for the denominator

        ii) loop over each word: do
            - add to denom the current learned prob of word-feature pair
                - if unseen (unmatched), add default prob (1/beta)
        done

        iii) loop over each word again: do
            - calculate alignment = (learned prob of word-feature pair + epsilon) / denom


5) 


Notes:
- words are given with syntactic category
- features are given iwth a number tag '#[0-9]'

